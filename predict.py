from music21 import converter, instrument, note, chord, stream
import glob
import numpy as np
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, LSTM, Activation
from keras import backend as K
from keras.optimizers import SGD
from keras.callbacks import ModelCheckpoint
from keras.utils import multi_gpu_model

notes = []
i = 0
for file in glob.glob("midi_songs/*.mid"):
	i += 1
	midi = converter.parse(file)
	notes_to_parse = None

	parts = instrument.partitionByInstrument(midi)
	if parts:
		notes_to_parse = parts.parts[0].recurse()
	else:
		notes_to_parse = midi.flat.notes

	for element in notes_to_parse:
		if isinstance(element, note.Note):
			notes.append(str(element.pitch))
		elif isinstance(element, chord.Chord):
			notes.append('.'.join(str(n) for n in element.normalOrder))


seq_num = 100
pitchnames = list(set([item for item in notes]))

notes_to_nums = dict((pitch,num) for num, pitch in enumerate(pitchnames))

pitch_size = len(pitchnames)
x_train = []
y_train = []

for i in range(0, len(notes) - seq_num):
	sequence_in = notes[i:i+seq_num]
	sequence_out = notes[i+seq_num]
	x_train.append([notes_to_nums[val] for val in sequence_in])
	y_train.append(notes_to_nums[sequence_out])

x_train = x_train
y_train = y_train
n_patterns = len(x_train)

x_train = np.reshape(x_train, (n_patterns, seq_num, 1))

x_train = x_train/float(pitch_size)

y_train = keras.utils.to_categorical(y_train, num_classes=pitch_size)

model = Sequential()
model.add(LSTM(512, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512))
model.add(Dense(256))
model.add(Dropout(0.3))
model.add(Dense(pitch_size))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')


# parallel_model = multi_gpu_model(model, gpus=None)
# parallel_model.compile(loss='categorical_crossentropy',optimizer='rmsprop')

# parallel_model.fit(x_train, y_train, epochs=20, batch_size=256)

# filepath = "weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5"    
# checkpoint = ModelCheckpoint(
#     filepath, monitor='loss', 
#     verbose=0,        
#     save_best_only=True,        
#     mode='min'
# )    
# callbacks_list = [checkpoint]     
# model.fit(x_train, y_train, epochs=100,batch_size=64)
# model_tojson = model.to_json()
# with open("model1.json", "w") as json_file:
#     json_file.write(model_json)
# # serialize weights to HDF5
# model.save_weights("model1.h5")
# print "Saved model to disk"

model.load_weights("w.hdf5")

start = np.random.randint(0, len(x_train)-1)
#get first sequence of notes
pattern = []
pattern = x_train[start]
# print len(pattern)
# # print pattern
# pattern = np.append(pattern, 1)
# print len(pattern)
int_to_notes = dict((num, note) for num, note in enumerate(pitchnames))
prediction_output = []
prev_output = 0
for _ in range(0, 500):
	pred_pattern = np.reshape(pattern, (1, len(pattern), 1))
	# pred_pattern = pred_pattern/float(pitch_size)

	prediction = model.predict(pred_pattern, verbose=0)
	noted = int_to_notes[np.argmax(prediction)]
	if noted == prev_output:
		start = np.random.randint(0,len(x_train) - 1)
		pattern = x_train[start]
		continue
	prev_output = noted
	prediction_output.append(noted)
	pattern = np.append(pattern, np.argmax(prediction))
	# print len(pattern)
	# pattern.append(np.argmax(prediction))
	pattern = pattern[1:len(pattern)]
	print len(pattern)


offset = 0
output_notes = []

# create note and chord objects based on the values generated by the model
for patt in prediction_output:
    # patt is a chord
    if ('.' in patt) or patt.isdigit():
        notes_in_chord = patt.split('.')
        notes = []
        for current_note in notes_in_chord:
            new_note = note.Note(int(current_note))
            new_note.storedInstrument = instrument.Piano()
            notes.append(new_note)
        new_chord = chord.Chord(notes)
        new_chord.offset = offset
        output_notes.append(new_chord)
    # patt is a note
    else:
        new_note = note.Note(patt)
        new_note.offset = offset
        new_note.storedInstrument = instrument.Piano()
        output_notes.append(new_note)
    # increase offset each iteration so that notes do not stack
    offset += 0.5

midi_stream = stream.Stream(output_notes)
midi_stream.write('midi', fp='output.mid')

